{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing https://en.wikipedia.org/wiki/Laplace_smoothing\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Empresa TESLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "import mpmath\n",
    "import matplotlib.pyplot as plt\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura dos arquivos em Excel\n",
    "TR1 = pd.read_excel('Treinamento1.xlsx')\n",
    "TS1 = pd.read_excel('Teste1.xlsx')\n",
    "TR2 = pd.read_excel('Treinamento2.xlsx')\n",
    "TS2 = pd.read_excel('Teste2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa(PD, coluna):\n",
    "    \n",
    "    tags =    [\"@\", \"#\", \"http\"]\n",
    "    \n",
    "    tabs =    [\"\\n\", \"\\t\"]\n",
    "    \n",
    "    pontos =  [\":\", \"/\", \"+\", \"-\", \"&\",\n",
    "               \"%\"]\n",
    "    \n",
    "    deletar = [\",\", \".\", \"?\", \"@\", \":\",\n",
    "               \";\", \"!\", \"'\", '\"', \"“\",\n",
    "               \"”\", \"#\", \"(\", \")\", \"…\",\n",
    "               \"/\", \"+\", \"-\", \"$\", \"&\",\n",
    "               \"%\", \"*\", \"[\", \"]\", \"{\",\n",
    "               \"}\", \"'s\"]\n",
    "    \n",
    "    lista_um = []\n",
    "    for frase in PD[coluna]:\n",
    "        frase = frase.split()\n",
    "        jumba = []\n",
    "        for palavra in frase:\n",
    "            jaca = palavra\n",
    "            if (\"tesla\" in palavra) or (\"tsla\" in palavra):\n",
    "                jaca = \"tesla\"\n",
    "            elif \"@\" in palavra:\n",
    "                jaca = \"\"\n",
    "            elif \"http\" in palavra:\n",
    "                jaca = \"\"\n",
    "            elif \"#\" in palavra:\n",
    "                jaca = \"\"\n",
    "            elif (palavra == frase[-1]) and (\"…\" in palavra):\n",
    "                jaca = \"\"\n",
    "   \n",
    "            jumba.append(jaca)\n",
    "        lista_um.append(\" \".join(jumba))\n",
    "        \n",
    "    lista_dois = []     \n",
    "    for frase in lista_um:\n",
    "        h = \"\"\n",
    "        for k in frase:\n",
    "            a = k\n",
    "            if k in UNICODE_EMOJI:\n",
    "                a = \" \"+ k + \" \"\n",
    "            elif k in pontos:\n",
    "                a = \" \"+ k + \" \"\n",
    "            elif k in tabs:\n",
    "                a = \" \"\n",
    "            h += a\n",
    "        lista_dois.append(h)\n",
    "    \n",
    "    lista_tres = []\n",
    "    for frase in lista_dois:\n",
    "        for n in deletar:\n",
    "            frase = frase.replace(n , \"\")\n",
    "        lista_tres.append(frase)\n",
    "        \n",
    "    lista_quatro = []\n",
    "    for frase in lista_tres:\n",
    "        frase = frase.split()\n",
    "        gogo = []\n",
    "        for palavra in frase:\n",
    "            if palavra in UNICODE_EMOJI:\n",
    "                palavra = palavra\n",
    "            elif len(palavra) <= 2:\n",
    "                palavra = \"\"\n",
    "            elif palavra == \"rt\":\n",
    "                palavra = \"\"\n",
    "            gogo.append(palavra)\n",
    "        lista_quatro.append(\" \".join(gogo))\n",
    "        \n",
    "    lista_cinco = []\n",
    "    z = 1\n",
    "    for frase in lista_quatro:\n",
    "        nano = \" \".join(frase.split())\n",
    "        if nano == \"\":\n",
    "            nano = \"tesla\"\n",
    "        lista_cinco.append(nano)\n",
    "    \n",
    "    PD[coluna]  = pd.Series((lista_cinco), index = PD.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vai(PD_treinamento, PD_teste, classificacaoes):\n",
    "    \n",
    "    supimpa = {\"Geral\":{}, \"Chance\": {}}\n",
    "    limpa(PD_treinamento, \"Tweets\")\n",
    "    limpa(PD_teste, \"Tweets\")\n",
    "    \n",
    "    for frase in PD_treinamento[\"Tweets\"]:\n",
    "        frase = frase.split()\n",
    "        for palavra in frase:\n",
    "            if palavra in supimpa[\"Geral\"]:\n",
    "                supimpa[\"Geral\"][palavra] += 1\n",
    "            else:\n",
    "                supimpa[\"Geral\"][palavra] = 1\n",
    "                \n",
    "    for classi in classificacaoes:\n",
    "        TTT = PD_treinamento[(PD_treinamento['Classificação']==classi)]\n",
    "        \n",
    "        supimpa[\"Chance\"][classi] = len(TTT['Classificação']) / len(PD_treinamento['Classificação'])\n",
    "        \n",
    "        supimpa[classi] = {}\n",
    "        for frase in TTT[\"Tweets\"]:\n",
    "            frase = frase.split()\n",
    "            for palavra in frase:\n",
    "                if palavra in supimpa[classi]:\n",
    "                    supimpa[classi][palavra] += 1\n",
    "                else:\n",
    "                    supimpa[classi][palavra] = 1  \n",
    "                    \n",
    "    numero_divisor = len(supimpa[\"Geral\"])\n",
    "    soma_geral = sum(supimpa[\"Geral\"].values())\n",
    "    for palavra in supimpa[\"Geral\"]:\n",
    "        supimpa[\"Geral\"][palavra] = (supimpa[\"Geral\"][palavra] + 1) / (soma_geral + numero_divisor)\n",
    "        \n",
    "    for classi in classificacaoes:\n",
    "        soma_classi = sum(supimpa[classi].values())\n",
    "        for palavra in supimpa[classi]:\n",
    "            supimpa[classi][palavra] = (supimpa[classi][palavra] + 1) / (soma_classi + numero_divisor)\n",
    "        supimpa[classi][\"palavra_nao_existe\"] = (1) / (soma_classi + numero_divisor)\n",
    "    \n",
    "    chances = {}\n",
    "    u = 1 \n",
    "    for frase in PD_teste[\"Tweets\"]:\n",
    "        chances[frase] = {}\n",
    "        frasum = frase.split()\n",
    "        for classi in classificacaoes:\n",
    "            probabilidade = mpmath.mpf(1.0)\n",
    "            for palavra in frasum:\n",
    "                if palavra in supimpa[classi]:\n",
    "                    probabilidade *= supimpa[classi][palavra]\n",
    "                else:\n",
    "                    probabilidade *= supimpa[classi][\"palavra_nao_existe\"]\n",
    "                    \n",
    "            chances[frase][classi] = probabilidade * supimpa[\"Chance\"][classi]\n",
    "    \n",
    "    lista_legal = []\n",
    "    for frase in PD_teste[\"Tweets\"]:\n",
    "        sugar = 0\n",
    "        valor = 0\n",
    "        for classi in classificacaoes:\n",
    "            if chances[frase][classi] > valor:\n",
    "                valor = chances[frase][classi]\n",
    "                sugar = classi\n",
    "        lista_legal.append(sugar) \n",
    "        \n",
    "    PD_teste[\"Naive-Bayes\"]  = pd.Series((lista_legal), index = PD_teste.index) \n",
    "    \n",
    "    lista_joia = []\n",
    "    for op in PD_teste['Classificação']:\n",
    "        lista_joia.append(op)\n",
    "        \n",
    "    \n",
    "    lista_uber = []\n",
    "    for d in range(len(lista_legal)):\n",
    "        if (lista_legal[d] == lista_joia[d]):\n",
    "            lista_uber.append(\"Verdadeiro\")\n",
    "        else:\n",
    "            lista_uber.append(\"Falso\")\n",
    "            \n",
    "    PD_teste[\"Final\"]  = pd.Series((lista_uber), index = PD_teste.index)  \n",
    "    \n",
    "    verdadeiro = 0\n",
    "    falso = 0\n",
    "    for i in range(len(lista_uber)):\n",
    "        if lista_uber[i] == \"Verdadeiro\":\n",
    "            verdadeiro += 1\n",
    "        else:\n",
    "            falso += 1\n",
    "    \n",
    "    duper = {}\n",
    "    for classi in classificacaoes:\n",
    "        duper[classi] = {}\n",
    "        for op in classificacaoes:\n",
    "            duper[classi][op] = 0\n",
    "            \n",
    "    \n",
    "    \n",
    "    for i in range(len(PD_teste['Classificação'])):\n",
    "        duper[PD_teste.loc[i, 'Classificação']][PD_teste.loc[i, \"Naive-Bayes\"]] += 1\n",
    "        \n",
    "        \n",
    "    for op in duper:\n",
    "        total = sum(duper[op].values())\n",
    "        for classi in duper[op]:\n",
    "            duper[op][classi] = duper[op][classi] / total\n",
    "\n",
    "    \n",
    "    taxa_de_acerto = (verdadeiro / len(lista_uber))\n",
    "    \n",
    "    return taxa_de_acerto, duper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostra(PD_treinamento, PD_teste, classificacaoes):\n",
    "    taxa, dicti = vai(PD_treinamento, PD_teste, classificacaoes)\n",
    "    print(\"Com {} categorias, esse classificador teve uma taxa de acerto geral de {:.2f}%\".format(, taxa * 100))\n",
    "    print(\"As taxas individuais seguem:\")\n",
    "    print(\"\\t\")\n",
    "    for op in dicti:\n",
    "        for classi in dicti[op]:\n",
    "            print(\"{:05.2f}% dos tweets {}s foram classificados como {}\".format(dicti[op][classi] * 100, op, classi))\n",
    "        print(\"\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esse classificador teve uma taxa de acerto geral de 84.00%\n",
      "As taxas individuais seguem:\n",
      "\t\n",
      "79.17% dos tweets Irrelevantes foram classificados como Irrelevante\n",
      "20.83% dos tweets Irrelevantes foram classificados como Relevante\n",
      "\t\n",
      "14.47% dos tweets Relevantes foram classificados como Irrelevante\n",
      "85.53% dos tweets Relevantes foram classificados como Relevante\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "mostra(TR1, TS1, [\"Irrelevante\", \"Relevante\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esse classificador teve uma taxa de acerto geral de 63.50%\n",
      "As taxas individuais seguem:\n",
      "\t\n",
      "45.83% dos tweets Irrelevantes foram classificados como Irrelevante\n",
      "04.17% dos tweets Irrelevantes foram classificados como Negativo\n",
      "29.17% dos tweets Irrelevantes foram classificados como Neutro\n",
      "20.83% dos tweets Irrelevantes foram classificados como Positivo\n",
      "\t\n",
      "03.23% dos tweets Negativos foram classificados como Irrelevante\n",
      "79.03% dos tweets Negativos foram classificados como Negativo\n",
      "14.52% dos tweets Negativos foram classificados como Neutro\n",
      "03.23% dos tweets Negativos foram classificados como Positivo\n",
      "\t\n",
      "06.25% dos tweets Neutros foram classificados como Irrelevante\n",
      "09.38% dos tweets Neutros foram classificados como Negativo\n",
      "64.06% dos tweets Neutros foram classificados como Neutro\n",
      "20.31% dos tweets Neutros foram classificados como Positivo\n",
      "\t\n",
      "03.85% dos tweets Positivos foram classificados como Irrelevante\n",
      "07.69% dos tweets Positivos foram classificados como Negativo\n",
      "30.77% dos tweets Positivos foram classificados como Neutro\n",
      "57.69% dos tweets Positivos foram classificados como Positivo\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "mostra(TR2, TS2, [\"Irrelevante\", \"Negativo\", \"Neutro\", \"Positivo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o código pronto e funcionando, concluiu-se que a empresa Tesla possui uma maior quantidade de mensagens Relevantes Verdadeiro (84%) do que Falsos (16%), o que demonstra que o código feito foi eficiente, pois conseguiu, dentre as opções de calssificação existentes, classificar os tweets da maneira adequada. E, tendo em vista o objetivo da empresa - melhorar seu marketing a fim de ampliar a divulgação e o consumo de seus produtos -, foi preferível obter todas as mensagens relevantes mesmo que com elas tenham vindo algumas não relevantes porque a porcentagem dessas dentre as demais foi pequena, possibilitando que esses dados sejam removidos manualmente.\n",
    "\n",
    "A empresa deveria seguir financiando o projeto, pois ele retorna o que o público alvo pensa sobre seus produtos e, com isso, saber o que deve ser aprimorado. E com mais verba seria possível aumentar o data base de tweets classificados, aumentando, assim, a probabilidade de acertos.\n",
    "\n",
    "Além de o projeto ajudar a Tesla, ele nos abre porta para as demais empresas, pois como nossa programação está escrito com funções, isso permite que analisamos não só os dados desse contexto quanto os demais.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
