{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing https://en.wikipedia.org/wiki/Laplace_smoothing\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Empresa TESLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "import mpmath\n",
    "import matplotlib.pyplot as plt\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /anaconda3/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura dos arquivos em Excel\n",
    "TR1 = pd.read_excel('Treinamento.xlsx')\n",
    "TS1 = pd.read_excel('Teste.xlsx')\n",
    "TR2 = pd.read_excel('Tweets.xlsx', sheet_name = 0)\n",
    "TS2 = pd.read_excel('Tweets.xlsx', sheet_name = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa(PD, coluna):\n",
    "    \n",
    "    tags =    [\"@\", \"#\", \"http\"]\n",
    "    \n",
    "    tabs =    [\"\\n\", \"\\t\"]\n",
    "    \n",
    "    pontos =  [\":\", \"/\", \"+\", \"-\", \"&\",\n",
    "               \"%\"]\n",
    "    \n",
    "    deletar = [\",\", \".\", \"?\", \"@\", \":\",\n",
    "               \";\", \"!\", \"'\", '\"', \"“\",\n",
    "               \"”\", \"#\", \"(\", \")\", \"…\",\n",
    "               \"/\", \"+\", \"-\", \"$\", \"&\",\n",
    "               \"%\", \"*\", \"[\", \"]\", \"{\",\n",
    "               \"}\", \"'s\"]\n",
    "    \n",
    "    lista_um = []\n",
    "    for frase in PD[coluna]:\n",
    "        frase = frase.split()\n",
    "        jumba = []\n",
    "        for palavra in frase:\n",
    "            jaca = palavra\n",
    "            if (\"tesla\" in palavra) or (\"tsla\" in palavra):\n",
    "                jaca = \"tesla\"\n",
    "            elif \"@\" in palavra:\n",
    "                jaca = \"\"\n",
    "            elif \"http\" in palavra:\n",
    "                jaca = \"\"\n",
    "            elif \"#\" in palavra:\n",
    "                jaca = \"\"\n",
    "            elif (palavra == frase[-1]) and (\"…\" in palavra):\n",
    "                jaca = \"\"\n",
    "   \n",
    "            jumba.append(jaca)\n",
    "        lista_um.append(\" \".join(jumba))\n",
    "        \n",
    "    lista_dois = []     \n",
    "    for frase in lista_um:\n",
    "        h = \"\"\n",
    "        for k in frase:\n",
    "            a = k\n",
    "            if k in UNICODE_EMOJI:\n",
    "                a = \" \"+ k + \" \"\n",
    "            elif k in pontos:\n",
    "                a = \" \"+ k + \" \"\n",
    "            elif k in tabs:\n",
    "                a = \" \"\n",
    "            h += a\n",
    "        lista_dois.append(h)\n",
    "    \n",
    "    lista_tres = []\n",
    "    for frase in lista_dois:\n",
    "        for n in deletar:\n",
    "            frase = frase.replace(n , \"\")\n",
    "        lista_tres.append(frase)\n",
    "        \n",
    "    lista_quatro = []\n",
    "    for frase in lista_tres:\n",
    "        frase = frase.split()\n",
    "        gogo = []\n",
    "        for palavra in frase:\n",
    "            if palavra in UNICODE_EMOJI:\n",
    "                palavra = palavra\n",
    "            elif len(palavra) <= 2:\n",
    "                palavra = \"\"\n",
    "            elif palavra == \"rt\":\n",
    "                palavra = \"\"\n",
    "            gogo.append(palavra)\n",
    "        lista_quatro.append(\" \".join(gogo))\n",
    "        \n",
    "    lista_cinco = []\n",
    "    z = 1\n",
    "    for frase in lista_quatro:\n",
    "        nano = \" \".join(frase.split())\n",
    "        if nano == \"\":\n",
    "            nano = \"tesla\"\n",
    "        lista_cinco.append(nano)\n",
    "    \n",
    "    PD[coluna]  = pd.Series((lista_cinco), index = PD.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vai(PD_treinamento, PD_teste, classificacaoes):\n",
    "    \n",
    "    supimpa = {\"Geral\":{}, \"Chance\": {}}\n",
    "    limpa(PD_treinamento, \"Tweets\")\n",
    "    limpa(PD_teste, \"Tweets\")\n",
    "    \n",
    "    for frase in PD_treinamento[\"Tweets\"]:\n",
    "        frase = frase.split()\n",
    "        for palavra in frase:\n",
    "            if palavra in supimpa[\"Geral\"]:\n",
    "                supimpa[\"Geral\"][palavra] += 1\n",
    "            else:\n",
    "                supimpa[\"Geral\"][palavra] = 1\n",
    "                \n",
    "    for n in range(len(classificacaoes)):\n",
    "        TTT = PD_treinamento[(PD_treinamento['Classificação']==n)]\n",
    "        \n",
    "        supimpa[\"Chance\"][classificacaoes[n]] = len(TTT['Classificação']) / len(PD_treinamento['Classificação'])\n",
    "        \n",
    "        supimpa[classificacaoes[n]] = {}\n",
    "        for frase in TTT[\"Tweets\"]:\n",
    "            frase = frase.split()\n",
    "            for palavra in frase:\n",
    "                if palavra in supimpa[classificacaoes[n]]:\n",
    "                    supimpa[classificacaoes[n]][palavra] += 1\n",
    "                else:\n",
    "                    supimpa[classificacaoes[n]][palavra] = 1  \n",
    "                    \n",
    "    numero_divisor = len(supimpa[\"Geral\"])\n",
    "    soma_geral = sum(supimpa[\"Geral\"].values())\n",
    "    for palavra in supimpa[\"Geral\"]:\n",
    "        supimpa[\"Geral\"][palavra] = (supimpa[\"Geral\"][palavra] + 1) / (soma_geral + numero_divisor)\n",
    "        \n",
    "    for classi in range(len(classificacaoes)):\n",
    "        soma_classi = sum(supimpa[classificacaoes[classi]].values())\n",
    "        for palavra in supimpa[classificacaoes[classi]]:\n",
    "            supimpa[classificacaoes[classi]][palavra] = (supimpa[classificacaoes[classi]][palavra] + 1) / (soma_classi + numero_divisor)\n",
    "        supimpa[classificacaoes[classi]][\"palavra_nao_existe\"] = (1) / (soma_classi + numero_divisor)\n",
    "    \n",
    "    chances = {}\n",
    "    u = 1 \n",
    "    for frase in PD_teste[\"Tweets\"]:\n",
    "        chances[frase] = {}\n",
    "        frasum = frase.split()\n",
    "        for classi in range(len(classificacaoes)):\n",
    "            probabilidade = mpmath.mpf(1.0)\n",
    "            for palavra in frasum:\n",
    "                if palavra in supimpa[classificacaoes[classi]]:\n",
    "                    probabilidade *= supimpa[classificacaoes[classi]][palavra]\n",
    "                else:\n",
    "                    probabilidade *= supimpa[classificacaoes[classi]][\"palavra_nao_existe\"]\n",
    "                    \n",
    "            chances[frase][classi] = probabilidade * supimpa[\"Chance\"][classificacaoes[classi]]\n",
    "    \n",
    "    lista_legal = []\n",
    "    for frase in PD_teste[\"Tweets\"]:\n",
    "        sugar = 0\n",
    "        valor = 0\n",
    "        for y in range(len(classificacaoes)):\n",
    "            if chances[frase][y] > valor:\n",
    "                valor = chances[frase][y]\n",
    "                sugar = y\n",
    "        lista_legal.append(sugar) \n",
    "        \n",
    "    PD_teste[\"Naive-Bayes\"]  = pd.Series((lista_legal), index = PD_teste.index) \n",
    "    \n",
    "    lista_joia = []\n",
    "    for op in PD_teste['Classificação']:\n",
    "        lista_joia.append(op)\n",
    "        \n",
    "    \n",
    "    lista_uber = []\n",
    "    for d in range(len(lista_legal)):\n",
    "        if (lista_legal[d] == lista_joia[d]):\n",
    "            lista_uber.append(\"Verdadeiro\")\n",
    "        else:\n",
    "            lista_uber.append(\"Falso\")\n",
    "            \n",
    "    PD_teste[\"Final\"]  = pd.Series((lista_uber), index = PD_teste.index)  \n",
    "    \n",
    "    verdadeiro = 0\n",
    "    falso = 0\n",
    "    for i in range(len(lista_uber)):\n",
    "        if lista_uber[i] == \"Verdadeiro\":\n",
    "            verdadeiro += 1\n",
    "        else:\n",
    "            falso += 1\n",
    "            \n",
    "    return (verdadeiro / len(lista_uber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esse classificador teve uma taxa de acerto de 84.0%\n"
     ]
    }
   ],
   "source": [
    "acerto = vai(TR1, TS1, [\"Irrelevante\", \"Relevante\"])\n",
    "print(\"Esse classificador teve uma taxa de acerto de {}%\".format(acerto * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esse classificador teve uma taxa de acerto de 63.5%\n"
     ]
    }
   ],
   "source": [
    "acerto = vai(TR2, TS2, [\"Irrelevante\", \"Negativo\", \"Neutro\", \"Positivo\"])\n",
    "print(\"Esse classificador teve uma taxa de acerto de {}%\".format(acerto * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'values_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5742e9657a70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTR2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'values_count'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o código pronto e funcionando, concluiu-se que a empresa Tesla possui uma maior quantidade de mensagens Relevantes Verdadeiro (%) do que Falsos (%), o que demonstra que o código feito foi eficiente, pois conseguiu, dentre as opções de calssificação existentes, classificar os tweets da maneira adequada. E, tendo em vista o objetivo da empresa - melhorar seu marketing a fim de ampliar a divulgação e o consumo de seus produtos -, foi preferível obter todas as mensagens relevantes mesmo que com elas tenham vindo algumas não relevantes porque a porcentagem dessas dentre as demais foi pequena, possibilitando que esses dados sejam removidos manualmente.\n",
    "\n",
    "A empresa deveria seguir financiando o projeto, pois ele retorna o que o público alvo pensa sobre seus produtos e, com isso, saber o que deve ser aprimorado. E com mais verba seria possível aumentar o data base de tweets classificados, aumentando, assim, a probabilidade de acertos.\n",
    "\n",
    "Além de o projeto ajudar a Tesla, ele nos abre porta para as demais empresas, pois como nossa programação está escrito com funções, isso permite que analisamos não só os dados desse contexto quanto os demais.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
